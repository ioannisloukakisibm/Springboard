{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "linear-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "successfully pulled 1 Triangle pages and 124 events\n",
      "We added 10 Carolina Theater events for a total of 134 Triangle events\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import docx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "api_key = input('Enter your API key')\n",
    "\n",
    "# pick up Carolina Theater separately, because for some reason it is not part of the Triangle locale. \n",
    "url = f'https://app.ticketmaster.com/discovery/v2/events.json?size=200&venueId=KovZpZAFAl6A&apikey={api_key}'\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "data=response.text\n",
    "\n",
    "parsed = json.loads(data)\n",
    "\n",
    "list_of_carolina_theater_events = parsed.get('_embedded').get('events')\n",
    "list_of_triangle_events = []\n",
    "index = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    url = f'https://app.ticketmaster.com/discovery/v2/events.json?page={index}&dmaId=366&size=200&apikey={api_key}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "    data=response.text\n",
    "\n",
    "    parsed = json.loads(data)\n",
    "\n",
    "    # Combine all the events\n",
    "    try:\n",
    "        list_of_triangle_events.extend(parsed.get('_embedded').get('events'))\n",
    "        index+=1\n",
    "    except:\n",
    "        print(\"successfully pulled\",index-1,\"Triangle pages and\",len(list_of_triangle_events), \"events\")\n",
    "        break\n",
    "\n",
    "list_of_triangle_events.extend(list_of_carolina_theater_events)\n",
    "\n",
    "print(\"We added\", len(list_of_carolina_theater_events), \"Carolina Theater events for a total of\", len(list_of_triangle_events), \"Triangle events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-convert",
   "metadata": {},
   "source": [
    "# GET EVENT INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aboriginal-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the events in a dataframe\n",
    "events = pd.DataFrame({'events':list_of_triangle_events})\n",
    "\n",
    "# Break the disctionaries into columns\n",
    "# Now we have 1 column for each sales, locale, dates, etc\n",
    "iteration_1 = events['events'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "handed-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the event names and add them to a dataframe\n",
    "list_of_event_names = [event.get('name') for event in list_of_triangle_events]\n",
    "list_of_event_ids = [event.get('id') for event in list_of_triangle_events]\n",
    "test = [event.get('test') for event in list_of_triangle_events]\n",
    "\n",
    "event_names_df = pd.DataFrame({'event name':list_of_event_names, 'event id':list_of_event_ids, 'is this entry a test?':test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-surrey",
   "metadata": {},
   "source": [
    "## VENUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "boolean-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_df = iteration_1._embedded.apply(pd.Series)\n",
    "\n",
    "list_of_venue_dictionaries = [embedded_df.venues[index][0] for index in range(len(embedded_df.venues))] \n",
    "\n",
    "venue_df = pd.DataFrame({'venue_dictionaries':list_of_venue_dictionaries})\n",
    "venue_final = pd.DataFrame(venue_df['venue_dictionaries'].apply(pd.Series)['name'])\n",
    "venue_final.rename({'name': 'venue name'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-socket",
   "metadata": {},
   "source": [
    "## SALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "departmental-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',500)\n",
    "\n",
    "# Break the sales column into columns\n",
    "# We now have public sales and presales\n",
    "sales = iteration_1.sales.apply(pd.Series)\n",
    "\n",
    "# Break the public sales into columns\n",
    "sales_public = sales.public.apply(pd.Series)\n",
    "\n",
    "# rename the public sales columns to distinguish them from the rest\n",
    "for col in sales_public.columns:\n",
    "    sales_public.rename({col:f'public sales {col}'}, axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "\n",
    "# Create a dataframe to add the final product of the steps below\n",
    "presale_final = pd.DataFrame()\n",
    "\n",
    "# Looping through the presales column to extract the information from the dictionaries\n",
    "# each presales row will have a dictionary with all the presale methods \n",
    "for presales_list_element in sales.presales:\n",
    "    \n",
    "# \"\"\"\n",
    "# If there is no presale, the entire rowcell will be NaN\n",
    "# In this case the pandas.isnull method will give us an error\n",
    "# We will need to add a new blank row in the except statement\n",
    "# We will also add a new column called 'blank' to make sure we don't mess the other columns names\n",
    "# The column will be dropped at the end\n",
    "# \"\"\"\n",
    "    try:\n",
    "        length = len(pd.isnull(presales_list_element))\n",
    "    except:\n",
    "        dict_holder_df = pd.DataFrame({'blank':[np.nan]})\n",
    "        presale_final = pd.concat([presale_final,dict_holder_df],axis=0)\n",
    "        continue\n",
    "\n",
    "# \"\"\"\n",
    "# The dictionaries will contain the name of the presale as well as the end and start date. \n",
    "# We need to extract the name and move it to the column names so that we can distinguish the start and end dates of each presale\n",
    "# \"\"\"\n",
    "    dict_holder_df = pd.DataFrame()\n",
    "    for presale_dict in presales_list_element:\n",
    "        \n",
    "        start_time_title = presale_dict['name'] + ' ' + list(presale_dict.keys())[0]\n",
    "        end_time_title = presale_dict['name'] + ' ' + list(presale_dict.keys())[1]\n",
    "        \n",
    "        holder_df = pd.DataFrame({start_time_title:[presale_dict['startDateTime']], end_time_title:[presale_dict['endDateTime']]})\n",
    "        dict_holder_df = pd.concat([dict_holder_df,holder_df], axis=1)\n",
    "        \n",
    "    presale_final = pd.concat([presale_final,dict_holder_df],axis=0)\n",
    "\n",
    "\n",
    "# Reset the index so that we can merge\n",
    "# drop the blank column\n",
    "presale_final.reset_index(inplace=True)\n",
    "presale_final.drop(columns=['index', 'blank'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-andrews",
   "metadata": {},
   "source": [
    "# DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "varied-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',500)\n",
    "\n",
    "# Break the dates column into columns\n",
    "# There are a lot of dates trapped into disctionaries. Use pd.Series multiple times to untangle everything\n",
    "dates = iteration_1.dates.apply(pd.Series)\n",
    "start_dates = dates.start.apply(pd.Series)\n",
    "status = dates.status.apply(pd.Series)\n",
    "initial_start_date = dates.initialStartDate.apply(pd.Series)\n",
    "\n",
    "# Make sure there are no weird columns created by pd.series\n",
    "initial_start_date = initial_start_date[['dateTime', 'localDate', 'localTime']]\n",
    "\n",
    "# rename the dates columns to distinguish them\n",
    "for col in start_dates.columns:\n",
    "    start_dates.rename({col:f'event start {col}'}, axis = 1, inplace = True)\n",
    "\n",
    "for col in initial_start_date.columns:\n",
    "    initial_start_date.rename({col:f'event initial start {col}'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-titanium",
   "metadata": {},
   "source": [
    "# CLASSIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "positive-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',500)\n",
    "\n",
    "list_of_classification_dictionaries = [iteration_1.classifications[index][0] for index in range(len(iteration_1.classifications))] \n",
    "\n",
    "classification_df = pd.DataFrame({'classification_dictionaries':list_of_classification_dictionaries})\n",
    "classification_df_broken_in_columns = classification_df['classification_dictionaries'].apply(pd.Series)\n",
    "\n",
    "\n",
    "classification_df_primary_family = classification_df_broken_in_columns[['primary', 'family']]\n",
    "columns_of_interest = list(classification_df_broken_in_columns.columns)\n",
    "columns_of_interest.remove('primary')\n",
    "columns_of_interest.remove('family')\n",
    "\n",
    "classification_df_final = pd.DataFrame()\n",
    "\n",
    "for column in columns_of_interest:\n",
    "    series_holder = classification_df_broken_in_columns[column].apply(pd.Series)\n",
    "    series_holder.drop(columns = ['id'], inplace=True)\n",
    "    series_holder.rename({series_holder.columns[0]:column}, inplace = True, axis = 1)\n",
    "    classification_df_final = pd.concat([classification_df_final,series_holder], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-insured",
   "metadata": {},
   "source": [
    "# PROMOTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "static-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break the promoters column into columns\n",
    "promoters = iteration_1.promoters.apply(pd.Series)\n",
    "\n",
    "for index in range(len(promoters.columns)):\n",
    "    promoters.rename({promoters.columns[index]: 'event promoter' + ' ' + str(promoters.columns[index]+1)}, axis = 1, inplace = True)\n",
    "\n",
    "promoters_df_final = pd.DataFrame()\n",
    "\n",
    "for column in promoters.columns:\n",
    "    series_holder = promoters[column].apply(pd.Series)\n",
    "    series_holder = series_holder[['name', 'description']]\n",
    "    series_holder.rename({'name':column + ' ' + 'name', 'description':column + ' ' + 'description'}, inplace = True, axis = 1)\n",
    "    promoters_df_final = pd.concat([promoters_df_final,series_holder], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-treasury",
   "metadata": {},
   "source": [
    "# PRICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "alleged-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the price information is missing from an event. \n",
    "# Replace NA with the word missing\n",
    "iteration_1.fillna({'priceRanges':'missing'}, inplace=True)\n",
    "\n",
    "\n",
    "# create a genberic pricing structure to replace the missing pricing information\n",
    "# set all prices to zero\n",
    "generic_pricing_structure = [{'type': 'standard', 'currency': 'USD', 'min': -1, 'max': -1}]        \n",
    "\n",
    "# Unfortunately the replace will get rid of the list part and replace everything with a 'naked' dictionary\n",
    "# Ideally we would have a list with the generic pricing dictionary as its only element\n",
    "test = iteration_1.replace({'missing':generic_pricing_structure})\n",
    "\n",
    "\n",
    "# The try-except step will fix this issue. \n",
    "# If we have a list with a dictionary inside, we will fetch the dictionary from inside the list\n",
    "# Otherwise we will fetch the dictionary directly \n",
    "list_of_pricerange_dictionaries = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    try:\n",
    "        x = row['priceRanges'].get('type')\n",
    "        list_of_pricerange_dictionaries.append(row['priceRanges'])\n",
    "    except:\n",
    "        list_of_pricerange_dictionaries.append(row['priceRanges'][0])\n",
    "\n",
    "        \n",
    "pricerange_df = pd.DataFrame({'pricerange_dictionaries':list_of_pricerange_dictionaries})\n",
    "pricerange_df_broken_in_columns = pricerange_df['pricerange_dictionaries'].apply(pd.Series)\n",
    "\n",
    "\n",
    "pricerange_df_broken_in_columns = pricerange_df_broken_in_columns[['type', 'min', 'max']]\n",
    "pricerange_df_broken_in_columns.rename({'type':'price type', 'min':'price min', 'max':'price max'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-walnut",
   "metadata": {},
   "source": [
    "# TICKET LIMIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "minus-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration_1.columns\n",
    "ticket_limit = pd.DataFrame(iteration_1['ticketLimit'].apply(pd.Series))\n",
    "ticket_limit = pd.DataFrame(ticket_limit['info']) \n",
    "ticket_limit.rename({'info':'ticket limit'},axis = 1, inplace = True)\n",
    "please_note = pd.DataFrame(iteration_1['pleaseNote'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-liver",
   "metadata": {},
   "source": [
    "# MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "varied-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price min</th>\n",
       "      <th>price max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.00</td>\n",
       "      <td>140.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>25.72</td>\n",
       "      <td>60.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>20.00</td>\n",
       "      <td>64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price min  price max\n",
       "0        -1.00      -1.00\n",
       "1        -1.00      -1.00\n",
       "2        -1.00      -1.00\n",
       "3        75.00     140.00\n",
       "4        -1.00      -1.00\n",
       "..         ...        ...\n",
       "129      25.72      60.37\n",
       "130      20.00      64.00\n",
       "131      23.40      32.70\n",
       "132      23.40      32.70\n",
       "133      23.40      32.70\n",
       "\n",
       "[134 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price min</th>\n",
       "      <th>price max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.00</td>\n",
       "      <td>140.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>25.72</td>\n",
       "      <td>60.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>20.00</td>\n",
       "      <td>64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>23.40</td>\n",
       "      <td>32.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price min  price max\n",
       "0        -1.00      -1.00\n",
       "1        -1.00      -1.00\n",
       "2        -1.00      -1.00\n",
       "3        75.00     140.00\n",
       "4        -1.00      -1.00\n",
       "..         ...        ...\n",
       "129      25.72      60.37\n",
       "130      20.00      64.00\n",
       "131      23.40      32.70\n",
       "132      23.40      32.70\n",
       "133      23.40      32.70\n",
       "\n",
       "[134 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = pd.concat([\n",
    "    event_names_df\n",
    "    ,venue_final\n",
    "    ,iteration_1['info']\n",
    "    ,sales_public\n",
    "    ,presale_final\n",
    "    ,start_dates\n",
    "    ,status\n",
    "    ,initial_start_date\n",
    "    ,classification_df_final\n",
    "    ,promoters_df_final\n",
    "    ,pricerange_df_broken_in_columns\n",
    "    ,ticket_limit\n",
    "    ,please_note\n",
    "    \n",
    "], axis = 1)\n",
    "\n",
    "list_of_groupby_columns = list(new_dataset.columns)\n",
    "\n",
    "datatypes_df = pd.DataFrame(new_dataset.dtypes, columns = ['data type']).reset_index()\n",
    "\n",
    "list_of_string_variables = list(datatypes_df[datatypes_df['data type'] == 'object']['index'])\n",
    "list_of_boolean_variables = list(datatypes_df[datatypes_df['data type'] == 'bool']['index'])\n",
    "list_of_numeric_variables = list(datatypes_df[datatypes_df['data type'] == 'float']['index'])\n",
    "\n",
    "new_dataset[['price min', 'price max']]\n",
    "\n",
    "for var in list_of_groupby_columns:\n",
    "    if var in list_of_string_variables:\n",
    "        new_dataset.fillna({var: '-1'}, inplace = True)\n",
    "    else:\n",
    "        new_dataset.fillna({var: -1}, inplace = True)\n",
    "        \n",
    "new_dataset[['price min', 'price max']]\n",
    "\n",
    "today_timestamp = pd.to_datetime(\"today\")\n",
    "today_date = today_timestamp.date()\n",
    "new_dataset['timestamp of data pull'] = today_timestamp\n",
    "new_dataset['date of data pull'] = today_date\n",
    "\n",
    "try:\n",
    "    current_dataset = pd.read_csv('final_ticketmaster_dataset.csv')\n",
    "    appended_dataset = pd.concat([current_dataset, new_dataset], axis = 0)\n",
    "    appended_dataset.drop(columns = [appended_dataset.columns[0]], inplace = True)\n",
    "\n",
    "    appended_dataset['timestamp of data pull'] = pd.to_datetime(appended_dataset['timestamp of data pull'])\n",
    "    appended_dataset['date of data pull'] = pd.to_datetime(appended_dataset['date of data pull'])\n",
    "\n",
    "    updated_dataset = appended_dataset.groupby(list_of_groupby_columns, as_index = False) \\\n",
    "    .agg({'date of data pull':'min', 'timestamp of data pull':'min'}) \n",
    "\n",
    "    updated_dataset.to_csv('final_ticketmaster_dataset.csv')\n",
    "\n",
    "    extra_events = updated_dataset['event id'].nunique() - current_dataset['event id'].nunique()  \n",
    "    extra_rows = updated_dataset.shape[0] - current_dataset.shape[0]  \n",
    "    print ('This pull resulted in', extra_rows, 'new rows')\n",
    "    print ('This pull resulted in', extra_events, 'new events')\n",
    "\n",
    "\n",
    "except:\n",
    "    new_dataset.to_csv('final_ticketmaster_dataset.csv')\n",
    "    print('except run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-programming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
